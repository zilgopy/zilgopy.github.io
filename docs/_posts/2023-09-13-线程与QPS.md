---
layout: post
title: 并发与QPS
tags: [QPS,IO,Thread]
---

# IO密集型和CPU密集型应用

我们经常听说IO密集型应用与CPU密集型应用.但是如何区分两者呢?

在多线程多处理器架构中,在处理每个请求时:

- cpu计算时间 $\lt$ IO操作处理时间, 则是IO密集型
- cpu计算时间 $\ge$ IO操作处理时间, 则是CPU密集型

例如一个web请求在处理时:
1. 首先进行本地内存计算花费5ms
2. 发送请求到后端服务,花费200ms
3. 收集请求返回结果,渲染模板15ms

那么在此过程中, CPU计算时间: 5ms + 15ms = 20ms , 等待IO操作时间: 200ms 说明这是个IO密集型的业务.

IO密集型的业务通常在请求量很高的情况下,应用的cpu占比可能很低,而IO操作的CPU占比可能很高.

CPU密集型的业务通常在请求量很高的情况下,应用的cpu占比可能非常高,而其它操作的CPU占比可能很低.

因此当讨论IO/CPU密集型时,需要切记:

- **讨论的主体是处理请求时CPU时间占总时间的比**
- 不能只考虑应用而忽略了其它操作所消耗的CPU

# 同步阻塞IO与异步非阻塞IO

当一个请求/任务到来之后, 需要占用cpu计算处理, 也可能需要链式调用其它服务或者访问磁盘IO. 在通常情况下应用层的操作都是同步阻塞.

**同步阻塞IO**: 当**线程**处理请求时,需要执行IO操作,此时线程内没有其它逻辑可运行,需要一直等待IO操作完成. 在此期间为了避免CPU时间浪费,将该线程的上下文封存,**将线程移入阻塞队列.**等到IO操作完成时,才重新将线程放入ready队列等待重新调度运行处理. 比如系统调用read /write读写文件, 或者等待网络IO readmsg/writemsg.

**异步非阻塞IO**: 当**线程**处理请求时,需要执行IO操作,此时线程将该请求放入一个事件队列中,然后执行下一个请求. 如果收到IO的事件,就重新将该请求调出并运行. 在此期间**线程可以一直运行直到本次时间片被用完或没有请求为止**.  比如使用libaio 读写文件, 或者nginx异步处理请求.

**协程同步非阻塞IO**: 协程是用户空间的轻量级线程,可以理解为封装过的请求. 当协程处理请求时,需要执行IO操作, 此时协程内没有其它可执行单元,需要一直等待IO操作完成.在此期间为了避免CPU时间浪费将该协程封存,处理其它协程的请求, **线程可以一直运行直到时间片用完或者所有协程都阻塞为止.** 比如goroutine的IO方式.

当我们讨论阻塞与非阻塞时,需要切记:

- **讨论的主体是线程,因为线程是CPU调度的最小单位**

# CPU使用率

cpu的使用情况是指在一定时间内使用的cpu与整体cpu的比值.  $Usage = \frac{Time\\_In\\_Use}{Meansure\\_Period}*100\% $

比如在监控周期1s内cpu 有50ms处于使用状态, 那其1s内的利用率 = 5%.

# 线程数计算

**多线程同步阻塞IO**

假如在多线程多处理的架构中,每当一个请求到达都会被分配到一个线程来处理,如果需要花费10ms 进行计算处理,然后 190ms用于等待网络/文件IO完成(同步IO), 那么在这个请求整个生命周期中cpu仅仅工作了10ms.

那么在一个8核cpu中,设置多少线程数能够最大化的利用cpu呢?  不考虑其它OS 以及softirq等线程的耗时情况下.

该请求真正CPU耗时10ms,总耗时200ms. 那么在整个200ms的监控周期中只有 $\frac{10ms}{10ms+190ms} = \frac1{20}$的时间在运行,cpu利用率5%.这与监控周期无关,如果1s内连续不断的处理请求,由于只有1/20的时间需要cpu,那么单线程的情况下cpu利用率也是5%,这样需要1/5%=20个线程不断地执行请求就可以保证单个cpu打满.那么在8核情况下 8*20 = 160 个线程就可以处理所有的连接.

即**线程数量 = $Core * \frac{IO\\_Wait + Compute}{Compute}$**

**异步非阻塞IO**

在异步非阻塞IO中, 每当一个请求到达都会被线程直接处理, 如果计算10ms, IO 虽然需要190ms,但是不用等待,CPU可以一直处于计算状态.因此CPU利用率在运行期间一直处于100%运行状态.即一个线程就可以打满单个CPU.

即**线程数量 = $Core$**

**协程同步非阻塞IO**

在协程非阻塞IO中,请求被线程的用户空间写成处理, 如果需要花费10ms 进行计算处理,然后 190ms用于等待网络/文件IO完成(同步IO). 虽然协程需要阻塞等待,但是线程可以继续运行以处理其它请求. 因此CPU利用率在运行期间可以一直处于100%状态,即单个线程就可以打满CPU.

过程中线程是非阻塞的,但协程是阻塞的.

因此**线程数量 = Core , 协程数量 = $Core * \frac{IO\\_Wait + Compute}{Compute}$**

> 相比多线程同步阻塞IO, 多协程/异步的好处:
>
> - 轻量级, 占用资源更少
> - 没有线程的上下文切换, 切换时间变少. 当并发量大时上下文切换也是一个比较耗时的操作.

# QPS计算

针对多线程同步阻塞IO的情况, 一个query 耗时200ms, 那么160个线程可以同时处理160个query .

那么 160 * 1000ms / 200 ms = 800 QPS

> 并发和并行的区别. 160个线程处理请求,可以理解为并发160. 
>
> 而实际上8个cpu同一时刻只能处理8个请求, 这就是并行. 
>
> 并发是逻辑单元,说明我们逻辑上可以同时处理多少请求, 而并行是并发+ 实际的硬件条件.

也就是通过并发线程数*每秒每个线程可以处理请求的个数 = QPS.

但是并发线程数也是计算出来的,简化一下得出:

QPS = $Core * \frac{IO\\_Wait + Compute}{Compute} * \frac{1000ms}{IO\\_Wait + Compute} = \frac{Core * 1000} {Compute} $

**即最大QPS与IO操作没有关系,只与请求中的计算时间有关.** 如果一个请求的计算时间是10ms, 那么 8核cpu的qps就是800. 与上面的结论相同.

该结论也可以引申到异步和协程模型中,同样适用.

那么要想提高qps就必须加配置, 同时添加线程数量, 以及优化程序逻辑减少cpu计算的时间.

> 该计算只是假设cpu 100% 用于处理请求的场景下的理论值, 实际操作系统还需要分一些cpu给内核执行内核函数,系统调用和softirq等.

# 限速

如果一个应用理论的QPS 是800 , 而后台服务的QPS是400, 可以通过降低并发,即降低线程的数量来实现:

如 160 线程/协程支持 800 qps ,那么将线程/协程数设置少一些 设置为80,那么qps就会被限制到400. 

不过这样通常会导致请求积压在自身, 客户也会感知到明显的请求延迟. 因此更好的办法是在请求入口处设置限速.
